{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/is_person_name', methods=['GET'])\n",
    "def is_person_name():\n",
    "    try:\n",
    "        data = request.args.get('txt') \n",
    "        text = data['text']\n",
    "\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "        doc = nlp(text)\n",
    "\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"PERSON\":\n",
    "                return jsonify({'is_person_name': True})\n",
    "\n",
    "        return jsonify({'is_person_name': False})\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)})\n",
    "\n",
    "\n",
    "def count_occurrences(soup, target_word): \n",
    "    vicinity_words = [\"book\", \"novel\", \"author\"] \n",
    "    content = soup.find('div', {'id': 'mw-content-text'}) \n",
    "    text = content.get_text().lower()\n",
    " \n",
    "    target_word_count = text.count(target_word.lower())\n",
    " \n",
    "    vicinity_counts = Counter()\n",
    "    for vicinity_word in vicinity_words:\n",
    "        vicinity_pattern = re.compile(fr'\\b{vicinity_word.lower()}\\b')\n",
    "        vicinity_counts[vicinity_word] = len(re.findall(vicinity_pattern, text))\n",
    "\n",
    "    return target_word_count, vicinity_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/search_wikipedia', methods=['GET'])\n",
    "def search_wikipedia():\n",
    "    try:\n",
    "        word = request.args.get('txt') \n",
    "\n",
    "        search_url = f'https://en.wikipedia.org/wiki/{word}'\n",
    "        response = requests.get(search_url)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            return jsonify({'error': f\"Failed to retrieve data. Status code: {response.status_code}\"})\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        if soup: \n",
    "            target_word_count, vicinity_counts = count_occurrences(soup, word)\n",
    "        \n",
    "            result = {\n",
    "                'word': word,\n",
    "                'target_word_count': target_word_count,\n",
    "                'vicinity_counts': dict(vicinity_counts)\n",
    "            }\n",
    "\n",
    "            return jsonify({'result': result})\n",
    "\n",
    "        return jsonify({'result': str(soup)})\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
